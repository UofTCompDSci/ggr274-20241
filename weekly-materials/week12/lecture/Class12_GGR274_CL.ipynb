{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e689b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Class 12\n",
    "\n",
    "## April. 2, 2024\n",
    "\n",
    "By the end of this class, you'll be able to:\n",
    "\n",
    "- Conduct spatial clustering analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28bd0b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Review of clustering\n",
    "\n",
    "## What is clustering? \n",
    "\n",
    "Clustering, generally, is the act of grouping similar things with eachother.\n",
    "\n",
    "We can do this with non-spatial data as well as spatial data. \n",
    "\n",
    "One common clustering method is k-means, which we won't cover in this class, but if you're interested, there's a nice tutorial on the method here: \n",
    "\n",
    "https://towardsdatascience.com/machine-learning-algorithms-part-9-k-means-example-in-python-f2ad05ed5203\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e360bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Spatial clustering, at a high level, is doing the same thing but one attribute to consider is geography. \n",
    "\n",
    "Spatial clustering involves looking at:\n",
    "\n",
    "- how some attribute is expressed across space; \n",
    "\n",
    "- whether similar attribute values are near each other. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256fb2b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Autocorrelation\n",
    "\n",
    "Autocorrelation literally means 'self correlations'. \n",
    "\n",
    "So instead of looking at how two attributes relate to each other (e.g., regression), we want to explore one a single attribute relates to its neighbours.\n",
    "\n",
    "Typically, we're talking about temporal autocorrelation or spatial autocorrelation.\n",
    "\n",
    "## Spatial Autocorrelation\n",
    "\n",
    "How does a variable value in a specific location correlate with the variable values in its neighbours?\n",
    "\n",
    "- regress a value on the values of its neighbours!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ab2e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1) For each observation (in this case, neighborhood) we need to know their neighbours!\n",
    "\n",
    "To do this we can create something known as a 'weights matrix'.\n",
    "\n",
    "A weights matrix is a matrix that describes whether or not any one observation is 'neighbours' with another.\n",
    "\n",
    "There are many ways we can do this, but let's focus on two common ones: queen's contiguity matrix and the rook's contiguity matrix:\n",
    "\n",
    "Queen's contiguity matrix define the neighbors as either shared edges or nodes, while rook's contiguity defines the neighbors as shared edges\n",
    "\n",
    "![weights matrices](https://i.stack.imgur.com/CWIHi.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d20826",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Think about: why the weights matrix can represent contiguity of neighbourhoods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac575d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2) Next we need to describe the value of our attribute of interest in neighbours\n",
    "\n",
    "To do this we create a variable known as 'spatial lag'. \n",
    "\n",
    "Spatial lag for neighbourhood *i* is often just the average of some attribute value across all of neighbourhood *i*'s neighbours (as determined by our weights matrix!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4876a88a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 3) Finally, now we can see how a neighbourhood's attribute compares to its neighbours. \n",
    "\n",
    "This set up allows us to see if neighbourhood's with high attribute values are next to other neighbourhoods with high values. \n",
    "\n",
    "We can then use a number of statistical tests to determine if there are 'significant' clusters in our dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe29f90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conducting spaital clusering analysis \n",
    "\n",
    "Let's see if we have spatial clusters in:\n",
    "1. the percent of adults with asthma in Toronto\n",
    "2. a random column of numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc690ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 1: import and merge DataFrame with Toronto's GeoDataFrame\n",
    "\n",
    "We have done this so many times! Let's do it one more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538df57",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d547b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Import and clean neighborhood geodata\n",
    "\n",
    "nbrhd = gpd.GeoDataFrame.from_file(\"Toronto_Neighbourhoods.geojson\")\n",
    "important_spat_cols = nbrhd.columns[[4, 5, 17]]\n",
    "colnames_spat = {important_spat_cols[0]: 'name',\n",
    "           important_spat_cols[1] : 'nbrhd_spat_id',\n",
    "           important_spat_cols[2] : 'geometry'}\n",
    "nbrhd_simple = nbrhd.copy()\n",
    "nbrhd_simple = nbrhd_simple[important_spat_cols]\n",
    "nbrhd_simple.rename(columns = colnames_spat, inplace=True)\n",
    "\n",
    "# remember to change the data type of neighbor id\n",
    "nbrhd_simple[\"Neighbid\"] = nbrhd_simple[\"nbrhd_spat_id\"].astype(int) \n",
    "nbrhd_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c4530",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Import and clean asthma data\n",
    "fname = '1_ahd_neighb_db_ast_hbp_mhv_copd_2007.xls'\n",
    "sname = '1_ahd_neighb_asthma_2007'\n",
    "asthma_neighb = pd.read_excel(fname, sheet_name = sname, header = 11)\n",
    "important_cols = asthma_neighb.columns[[0, 1, 10, 11]] \n",
    "colnames = {important_cols[0] : 'Neighbid', \n",
    "            important_cols[1] : 'name', \n",
    "            important_cols[2] : 'adult_pop',\n",
    "            important_cols[3] : 'asthma_pct'}\n",
    "asthma_rates = asthma_neighb.copy()\n",
    "asthma_rates = asthma_rates[important_cols]\n",
    "asthma_rates.rename(columns = colnames, inplace=True)\n",
    "asthma_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72157271",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the DataFrame to GeoDataFrame\n",
    "nbrhd_simple = nbrhd_simple.merge(asthma_rates, on=\"Neighbid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd6f84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before we start doing cluster analysis, we create a column of random numbers to our neighbor GeoDataFrame\n",
    "\n",
    "This is to generate a *random spatial pattern* in our Toronto dataset.\n",
    "\n",
    "We **shouldn't** expect any spatial clusters in this random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ed941",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nbrhd_simple['randNumCol'] = np.random.randint(1, 101, nbrhd_simple.shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize = (12,12))\n",
    "nbrhd_simple.plot(column = \"randNumCol\", cmap = 'YlOrRd', scheme='quantiles', k=5, ax=axes[0])\n",
    "nbrhd_simple.plot(column = \"asthma_pct\", scheme='quantiles', k=5, cmap = 'YlOrRd', ax=axes[1])\n",
    "axes[0].set_title(\"Random numbers\", fontsize = 20)\n",
    "axes[1].set_title(\"Asthma percentage\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fbf05a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 2: Identify the neighbours\n",
    "\n",
    "We will use the package [`libpysal`](https://pysal.org/libpysal/) to complete this task.\n",
    "\n",
    "The neighbours of neighbourhoods are also knowns as \"weight matrix\".\n",
    "\n",
    "We will use the Queen's contiguity weight.\n",
    "\n",
    "Before creating weight matrix, we need to project the gdf into a projection coordinate system (e.g., Web Mercator). We will not cover it in detail in this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92976039",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import libpysal as lps\n",
    "# Reproject the gdf to 'Web Mercator'\n",
    "nbrhd_simple = nbrhd_simple.to_crs(\"EPSG:3857\")\n",
    "\n",
    "# Create the spatial weights matrix\n",
    "w = lps.weights.Queen.from_dataframe(nbrhd_simple)\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize = (12,12))\n",
    "# add nbrhd map\n",
    "nbrhd_simple.plot(ax = axes, edgecolor = 'black', facecolor = 'w')\n",
    "# show what weights look like\n",
    "w.plot(nbrhd_simple, ax=axes, \n",
    "        edge_kws=dict(color='r', linewidth=1),\n",
    "        node_kws=dict(marker=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe707b45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's inspect the weights matrix further. What does it look like: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3b349d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The first neighborhood has 5 neighbours: 128, 1, 133, 134, and 55\n",
    "\n",
    "(And the weight of each neighbour is 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2ff77",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "w[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3452972",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nbrhd_simple['name_y'][[0,128,1,133,134,55]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f7705",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "first_neighborhood = nbrhd_simple.loc[[0]]\n",
    "first_neighbors = nbrhd_simple.loc[[128,1,133,134,55]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,1, figsize = (12,12))\n",
    "nbrhd_simple.plot(ax = axes, edgecolor = 'black', facecolor = 'w')\n",
    "first_neighborhood.plot(ax=axes, facecolor = 'b')\n",
    "first_neighbors.plot(ax = axes, facecolor='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11227e92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "let's see if 128 is also connected to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbe7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "w[128] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ba10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_neighborhood = nbrhd_simple.loc[[128]]\n",
    "target_neighbors = nbrhd_simple.loc[[0,16,4,134,55,62]]\n",
    "\n",
    "fig, axes = plt.subplots(1,1, figsize = (12,12))\n",
    "nbrhd_simple.plot(ax = axes, edgecolor = 'black', facecolor = 'w')\n",
    "target_neighborhood.plot(ax=axes, facecolor = 'b')\n",
    "target_neighbors.plot(ax = axes, facecolor='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0a4a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also look at the distribution of connections using the built in weights histogram function.\n",
    "\n",
    "The first number is the count of connections and the second number is the number of neighbourhoods with this count of connections. \n",
    "\n",
    "For example, there are 9 neighbourhoods with 3 connections, 13 with 4 connections, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bad3edb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Finally let's 'row standardize' our matrix so that each nbrhd's connections sum to one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c123ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row standardize the matrix\n",
    "w.transform = 'R'\n",
    "\n",
    "#how did this change things?\n",
    "print('weights for nbrhd 0: ', w[0])\n",
    "print('weights for nbrhd 128: ', w[128])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d107502",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 3: Now that we have spatial weights established, we can calculate the average value of the neighbours of each neighbourhood, aka spatial lag.\n",
    "\n",
    "Let's do that for the asthma percentage `asthma_pct` and for the random numbers `randNumCol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c78a9b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# calculate the average of asthma_pct attribute of neighbours, then store in a new column\n",
    "\n",
    "nbrhd_simple['w_asthma_pct'] = lps.weights.lag_spatial(w, nbrhd_simple['asthma_pct'])\n",
    "nbrhd_simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e8db3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's look at a scatter plot between asthma_pct in each neighbourhood vs. the avg asthma_pct in their neighbors.\n",
    "\n",
    "Recall our scatter plot in the regression class.\n",
    "\n",
    "Keep in mind: we say spatial clustering is a kind of spatial autocorrelation, so the independent variable (x) is the target variable, while the dependent variable (y) is its *spatial lag*.\n",
    "\n",
    "What relationships can you identify from the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f383fa0d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nbrhd_simple.plot.scatter(x = \"asthma_pct\", y = \"w_asthma_pct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee3a8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's repeat the above, but for our random number column we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c682ffe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nbrhd_simple['w_randNumCol'] = lps.weights.lag_spatial(w, nbrhd_simple['randNumCol'])\n",
    "nbrhd_simple.plot.scatter(x = \"randNumCol\", y = \"w_randNumCol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586eabed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So what do we see in the above two scatterplots?\n",
    "\n",
    "- As `asthma_pct` in a specific neighbourhood gets larger, the average value of `asthma_pct` in that neighbhourhood's neighbours *(gets smaller/gets bigger/doesn't change)*.\n",
    " \n",
    "- As `randNumCol` in a specific neighbourhood gets larger, the average value of `randNumCol` in that neighbhourhood's neighbours *(gets smaller/gets bigger/doesn't change)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "nbrhd_simple.plot.scatter(x = \"asthma_pct\", y = \"w_asthma_pct\", ax=axes[0])\n",
    "nbrhd_simple.plot.scatter(x = \"randNumCol\", y = \"w_randNumCol\", ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c02c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 4: Using a unique indicator to test the spatial autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499f30f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Moran's I\n",
    "Moran's I is global spatial autocorrelation statistic that tells us if high values are next to high values and low values are next to low values. \n",
    "\n",
    "There is also a way to determine if this occurs at a significan level - e.g., does this sorting happen more than expected if the values were randomly spread across our study area.\n",
    "\n",
    "The value of Moran's I ranges from -1 to 1, where I of 1 is perfectly clustered and -1 is perfectly 'dispersed' (clustered and dispersed are two typical spatial patterns)\n",
    "\n",
    "![example of morans I](https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20200421144010724-0711:9781108614528:49898fig4_1.png)\n",
    "\n",
    "**Ho (null hypothesis) = the values of asthma_pct are randomly distributed across our study area**\n",
    "\n",
    "**Ha (alternative hypothesis) = the values of asthma_pct are not randomly distributed** \n",
    "\n",
    "If our p value is < 0.05 we will reject our null hypothesis Ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b022ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will use a new package `esda` [\"Exploratory Spatial Data Analysis\"](https://pysal.org/esda/) to calculate Moran's I.\n",
    "\n",
    "Another package [`splot`](https://splot.readthedocs.io/en/latest/) is to visualize the output.\n",
    "\n",
    "The pacakage automatically calculate the spaital lag using our spatial weight matrix `w`.\n",
    "\n",
    "You can also find more inforamtion of Moran's I [here](https://en.wikipedia.org/wiki/Moran%27s_I). Roughly speaking, Moran's I is a weighted autocorrelation statstic.\n",
    "\n",
    "You can also relate the process to do a regression between the targe variable and its spatial lags, while the Moran's I is like the correlation coefficient (but not exactly the same!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf9f372",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's firstly try regressing the spatial lag `w_asthma_pct` on the attribute `asthma_pct`.\n",
    "\n",
    "The coefficient is significant, indicating a high possibility of significant Moran's I!\n",
    "\n",
    "In addition, the coefficient is >0, indicating that a high value is potentially surrounding by high value, vice versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b7bd8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "reg = ols('w_asthma_pct ~ asthma_pct', data = nbrhd_simple).fit()\n",
    "reg_sum = reg.summary()\n",
    "reg_sum.tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc6784f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import esda\n",
    "import splot\n",
    "from splot.esda import moran_scatterplot\n",
    "\n",
    "mi = esda.Moran(nbrhd_simple['asthma_pct'], w)\n",
    "\n",
    "print('The Morans I value is: ', mi.I)\n",
    "print('The p-value of this Morans I value is: ', mi.p_sim)\n",
    "\n",
    "#visualize!\n",
    "splot.esda.moran_scatterplot(mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6fd316",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "The Moran's plot shows us the same scatter we saw before except now they've standardized the variable value and the spatial lag values (aka made them z-scores, where 0 is average). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df3761",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can furtherly break the scatterplot into 4 quadrants - going counter clockwise, starting from the upper-right. \n",
    "\n",
    "1. The upper right is the 'high-high' quadrant, where high values in a nbrhd are next to neighbours with high values (quadrant 1)\n",
    "2. The upper left is the 'low-high' quadrant, where low values in a nbrhd are next to neighbours with high values (quadrant 2)\n",
    "3. The lower left is the 'low-low' quadrant (quadrant 3)\n",
    "4. The lower right is the 'high-low' quadrant (quadrant 4)\n",
    "\n",
    "\n",
    "If most points in our scatterplot are in the high-high and low-low quadrants we probably have clustering. \n",
    "\n",
    "If they are mostly in the low-high and high-low then there's likely dispersal. \n",
    "\n",
    "If there is no obvious pattern, then there's no sptial pattern - random distributed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911ec6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's do it again with the random numbers column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b540218",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_randNumCol = esda.Moran(nbrhd_simple['randNumCol'], w)\n",
    "\n",
    "print('The Morans I value is: ', mi_randNumCol.I)\n",
    "print('The p-value of this Morans I value is: ', mi_randNumCol.p_sim)\n",
    "\n",
    "#visualize!\n",
    "splot.esda.moran_scatterplot(mi_randNumCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9e9fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Make the comparison\n",
    "fig, axes = plt.subplots(1,2, figsize = (12,12))\n",
    "splot.esda.moran_scatterplot(mi, ax=axes[0])\n",
    "splot.esda.moran_scatterplot(mi_randNumCol, ax=axes[1])\n",
    "\n",
    "axes[0].set_title(\"Asthma percentage\", fontsize = 20)\n",
    "axes[1].set_title(\"Random numbers\", fontsize = 20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e099e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Local Spatial Autocorrelation\n",
    "\n",
    "### Step 5: identify the clusters\n",
    "\n",
    "When Moran's I is significant (i.e., <0.05), we can say there is a significant spatial autocorrelation for the variable.\n",
    "\n",
    "More specifically, we can say there is a pattern of spatial clustering (Moran's I significant and >0) of asthma percentage in Toronto neighborhooods!\n",
    "\n",
    "**But WHERE are the clusters?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bfa5e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use a different statistic to identify significant incidents of the clusters, i.e., **local indicators of spatial autocorrelation (LISA)**. \n",
    "\n",
    "This tells us exactly where on the map this clustering is happening!\n",
    "\n",
    "We can think about the Moran's I plots to help us here. \n",
    "\n",
    "Using a new function we can identify which quadrant each neighbourhood is in, and if the relationship to neighbourhing values is strong enough to be significant. \n",
    "\n",
    "For our case, those observations in quadrant 1 and 3 are 'clustered' and those in 2 and 4 would be 'outliers'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820b197",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print('The Morans I value is: ', mi.I)\n",
    "print('The p-value of this Morans I value is: ', mi.p_sim)\n",
    "splot.esda.moran_scatterplot(mi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59d14a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `Moran_Local` function help us to generate a statistic for each neighbourhood.\n",
    "\n",
    "We want to name the reult as `lisa`, because lisa (local indicators of spatial association)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ac2718",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "lisa = esda.Moran_Local(nbrhd_simple['asthma_pct'], w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d21ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It has two attributes: `.p_sim` store the significace, `.q` store which quadrant the neighbourhoods belong to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b5193",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Break observations into significant or not\n",
    "nbrhd_simple['significant'] = (lisa.p_sim < 0.05)\n",
    "\n",
    "# Store the quadrant they belong to\n",
    "nbrhd_simple['quadrant'] = lisa.q\n",
    "nbrhd_simple[['asthma_pct','w_asthma_pct','significant','quadrant']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb0188",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use a built in function in splot to plot the results, but this map is kind of ugly...\n",
    "\n",
    "Here, the \"HH\" means \"High-High\", i.e., high values surrounding by high values;\n",
    "\n",
    "\"HL\" means \"High-Low\"... \"ns\" means \"no significnat\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc61093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import lisa_cluster\n",
    "splot.esda.lisa_cluster(lisa, nbrhd_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e01e17c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use what we learned before to plot the result of local autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17954c80",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Setup the figure and axis\n",
    "fig, axes = plt.subplots(1,1, figsize=(12, 12))\n",
    "\n",
    "# Plot insignificant clusters\n",
    "ns = nbrhd_simple.loc[nbrhd_simple['significant']==False, 'geometry']\n",
    "ns.plot(ax=axes, color='white', edgecolor='grey')\n",
    "\n",
    "# Plot HH clusters\n",
    "hh = nbrhd_simple.loc[(nbrhd_simple['quadrant']==1) & (nbrhd_simple['significant']==True), 'geometry']\n",
    "hh.plot(ax=axes, color='red', edgecolor='grey')\n",
    "\n",
    "# Plot LL clusters\n",
    "ll = nbrhd_simple.loc[(nbrhd_simple['quadrant']==3) & (nbrhd_simple['significant']==True), 'geometry']\n",
    "ll.plot(ax=axes, color='blue', edgecolor='grey')\n",
    "\n",
    "# Plot LH clusters\n",
    "lh = nbrhd_simple.loc[(nbrhd_simple['quadrant']==2) & (nbrhd_simple['significant']==True), 'geometry']\n",
    "lh.plot(ax=axes, color='lightblue', edgecolor='grey')\n",
    "\n",
    "# Plot HL clusters\n",
    "hl = nbrhd_simple.loc[(nbrhd_simple['quadrant']==4) & (nbrhd_simple['significant']==True), 'geometry']\n",
    "hl.plot(ax=axes, color='salmon', edgecolor='grey')\n",
    "\n",
    "# Style and draw\n",
    "axes.set_title(\"Adult Asthma Percentages\", fontsize = 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123eeb9d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Finally, one more built in plot if you want!**\n",
    "\n",
    "- It automatcially plot the local Moran's I scatter (the Moron's I plot but identify the significant neighbourhoods);\n",
    "\n",
    "- the types and locations of the significant neighbourhoods;\n",
    "\n",
    "- and the choropleth of the original variable in 5 quantiles (the asthema percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cd9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import plot_local_autocorrelation\n",
    "splot.esda.plot_local_autocorrelation(lisa, nbrhd_simple, 'asthma_pct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef9e90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Finally finally, let's look at what the random number col looks like...**\n",
    "\n",
    "Even random distributions of data across space will sometime generate local clusters.\n",
    "\n",
    "It's always good to consider the GLOBAL and LOCAL measures of spatial autocorrelation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0229d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lisa_randNumCol = esda.Moran_Local(nbrhd_simple['randNumCol'], w)\n",
    "splot.esda.plot_local_autocorrelation(lisa_randNumCol, nbrhd_simple, 'randNumCol')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c7071",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### One more thing, let us do an exercise!\n",
    "\n",
    "[exercise](Exercise/Cluster_analysis_exercise.ipynb)\n",
    "\n",
    "[exercise_solusion](Exercise/Cluster_analysis_solusion.ipynb)\n",
    "\n",
    "(Solusion will be available on Wednesday)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
